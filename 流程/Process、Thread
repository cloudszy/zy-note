## 线程、进程篇

        1.对于系统来说，一个任务就是一个进程，一个进程至少有一个线程
        2.实现多任务有3种方式，多进程模式、多线程模式、多进程加多线程模式。
        3.线程是最小的折行单元，如何调度进程和线程，完全由系统决定，程序自己不能决定什么时候执行，执行多长时间。
        
        * 多进程 
        
          1.Unix/Linux操作系统提供了一个fork()系统调用，fork()函数调用一次返回2次。系统把当前进程(父进程)复制一份(为子进程)
          2.子进程永远返回0，而父进程则返回子进程的ID(系统编号)。
          3.父进程可以fork出多个子进程，父进程记住每个子进程的ID，而子进程调用getppid则可以拿到父进程的ID
        
          # multiprocess.py
        
          import os # 导入系统模块
          
          print 'Process (%s) start...' % os.getpid()  # 打印一个（获取当前系统进程，父进程）
          
          pid = os.fork() # 复制一个子进程
          
          if pid == 0: # 子进程等于0时
            
            print 'I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid) # 子进程返回0，继续执行，获取子进程、父进程
            
          else:
          
            print 'I (%s) just created a child proess (%s).' % (os.getpid(), pid) # 获取当前系统进程ID和子进程。
            
            
        # multiprocessing 多进程包
        
          1.Windows没有fork调用，需要用到multiprocessing模块(跨平台的多进程模块)
          2.multiprocessing模块提供了一个Process类代表一个进程对象
          
          * from multipocessing import Process
            
            import os
            
            def run_proc(name):
              
              print 'run chid process %s (%s)...' % (name, os.getpid())
              
             if __name__=='__main__':
              
                print 'Parent process %s.' % os.getpid()
                
                p = Process(target = run_proc, args = ('test',))
                
                print 'Process will start.'
                
                p = start()
                
                p.join()
                
                print 'Process end.'
                
                # 1.创建子进程时，只要传入一个执行函数和函数参数，创建一个Process实例，用start()方法启动
                # 2.join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。
                
                
              # Pool 进程池
              
                * from multiprocessing import Pool
                
                  import os, time, random       # 系统 时间 随机 模块
                  
                  def long_time_task(name):
                  
                    print 'Run task %s (%s)...' % (name, os.getpid())       # 打印一个(当前进程的名字)
                    
                    start = time.time()      # 起始时间
                    
                    time.sleep(random.random() * 3) # 休眠时间随机 
                    
                    end = time.time（）  # 结束时间
                    
                    print 'Task %s runs %0.2f seconds.' % (name, (end  - start))  # 打印（名字，结束时间-起始时间）
                    
                   if __name__=='__main__':
                    
                      print 'Parent process %s.' % os.getpid()  # 打印 当前进程ID
                    
                      p = pool()    # 把pool赋值给变量p
                    
                      for i in range(5):  # 循环变量5次
                        
                         p.apply_async(long_time_task, args = (i,))  # 
                         
                      print 'Waiting for all subprocesses done...'
                      
                      p.close()
                      
                      p.join()
                      
                      print 'ALL subprocesses done.'
                      
                      
                      # 1.对pool对象调用join()方法会等待所有子进程执行完毕，调用ioin()之前必须调用close()，
                        2.调用close()之后就不能继续添加新的Process
                        3.pool默认大小在我的电脑上是4，因此最多同时执行4个进程，改成p = Pool(5)，就可以同时跑5个进程
                        
                 # 进程间通信 (Queue/pipes)   
                 
                       from multiprocessing import process, Queue
                       
                       import os, time, random
                       
                       # 写数据进程执行的代码：
                       
                       
                       def write(q):
                       
                          for value in ['A', 'B', 'c']:        
                          
                                print 'Put %s to queue...' % value    循环打印 "ABC"
                                
                                q.put(value)
                                
                                time.sleep(random.random())     间隔时间随机
                         
                         # 读数据进程折行的代码：
                         
                        def read(q):
                        
                                while = True:     循环为真，永远循环
                                
                                value = q.get(True)
                                
                                print 'Get %s from queue. ' % value
                                
                        
                        if__name__=='__main__':
                        
                        # 父进程创建Queue，并传给各个子进程：
                        
                                q = Queue()
                                
                                pw = Process(target = write, args = (q,))  
                                
                                pr = Process(target = read, args = (q,))
                                
                                pw.start() # 启动子进程pw，写入
                                
                                pr.start() # 启动子进程pr，读取
                                
                                pw.join()  # 等待pw结束
                                
                                pr.terminate() # pr进程里是死循环，无法等待其结束，只能强行终止
                                
                         # 1. 在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节
                           2. 父进程所以Python对象必须通过pickle序列化再传到子进程去
                           3. 如果multiprocessing在windows下调用失败，要优先考虑是不是pickle失败了
                           
                           
                        # 小结
                        
                           1.在Unix/linux下，可以使用fork()实现多进程
                           2.要实现跨平台的多进程，可以使用multiprocessing模块
                           3.进程间通信是通过Queue、pipes等实现的
                           
                           
                    # 多线程 (Thread)
                    
                      1.多任务可以由多进程完成，也可以由一个进程的多线程完成。
                      2.启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行
                      
                      import time, threading  # 导入时间、多线程模块
                      
                      def loop():  
                      
                        print 'thread %s is running...' % threading.current_thread().name  # 打印（获取子线程实例，名字。）
                        
                        n = 0
                        
                        while n < 5:  N大于5时跳出循环
                        
                                n = n + 1
                                
                                print 'thread %s ended.' % (threading.current_thread().name, n)  # 循环打印（5个子进程实例，名字。）
                                
                                time,sleep(1)   #  时间间隔 1秒
                                
                         print 'thread %s ended.' % threading.current_thread().name  #  子进程 结束 
                         
                       pritn 'thread %s is running...' threading.current_thread().name  # 打印（获取当前线程，为主线程，名为'MainThread'）
                       
                       t = threading.Thread(target = loop, name = 'LoopThread')  # 创建一个子线程实例，目标是Loop，子线程名字为'~'
                       
                       t.start() # 子进程开始
                       
                       t.join() #  子进程结束
                       
                       print 'thread %s ended.' % threading.current_thread().name # 父进程 结束
                       
                       
                       # 1.由于任何进程会默认启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程。
                         2.threading模块有个current_thread()的函数，它永远返回当前线程实例。
                         3.主线程实例的名字'MainThread'，子线程名字创建时可以指定'LoopThread'，系统默认为'Thread-1，-2...'
                         
                         
                    # Lock 线程锁
                    
                         1.多线程和多进程最大的'不同'在于，多进程中，同一个变量，各自有一份拷贝存在每个进程中，互不影响。
                         2.而多进程中，所有变量都由所有线程共享，任何一个变量都可以被任何一个线程修改
                         3.因此，线程之前共享数据最大的危险在于多个线程同时改一个变量
                         
                       * import time, threading  # 导入时间 子线程模块
                       
                         balance = 0     # 声明一个变量为0，存款。
                         
                         def change_it(n):  # 定义一个函数    先存后取，结果应该一直为0
                         
                                global balance #  global--将变量定义为全局变量
                                
                                balance = balance + n
                                
                                balance = balance - n
                                
                        def run_thread(n):  
                         
                                for i in range(100000):    把change_it函数，循环100000次
                                
                                        change_it(n)
                                        
                        t1 = threading.Thread(target = run_thread, args = (5,)) # 创建子线程t1，传入函数，和参数
                        
                        t2 = threading.Thread(target = run_thread, args = (8,)) # 创建子线程t2，传入函数，和参数
                        
                        t1.start()  # 子线程t1，开始
                        
                        t2.start()  # 子线程t2，开始
                        
                        t1.join()   # 结束
                        
                        t2.join()   # 结束
                        
                        print balance  # 打印  最后存款
                        
                        
                     # 1.由于t1，t2两条子线程是交替运营，所以循环次数果断的话，结果不一定为0.
                       2.如果要确保balance计算正确，就要给change_it()上一把锁
                       3.当某个线程开始执行change_it()时，该线程因为获得了锁，因此其他线程不能同时执行change_it()
                       4.只能等待，知道锁被释放后，获得该锁以后才能修改
                       4.由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以不会造成修改冲突
                       5.创建一个锁就是通过threading.lock()实现
                       
                       
                    balance = 0
                    
                    lock = threading.lock()    # 声明一把锁
                    
                    def run_thread(n):
                    
                        for i in range(100000):
                        
                                lock.acquire()   # 先要获取锁
                                
                                try:                                    #  确保锁一定会释放
                                
                                        change_it(n) 
                                       
                                finally:
                                
                                        lock.release() # 释放锁
                                        
                                        
                                        
                   # 1.当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程继续等待直到获得锁为止。
                     2.获的锁的线程用完后一定要释放锁，否则等待锁的线程将永远等待下去，所以try...finally来确保锁一定会释放。
                     
                     
                     
                     
                # 小结：
                
                     1.多线程编程，模型复杂，容易发生，必须用锁加以隔离，同时，又要小心死锁的发生。
                     2.Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。
                     
                     
                     
                # ThreadLocal
                
                 # 1. 在多线程环境下，每个线程都有自己的数据。
                   2.一个线程使用自己的全部变量比使用全局变量好
                   2.因为局部变量只有线程自己能看见，不会影响其他线程而全局变量的修改必须加锁
                
                  * def process_stduent(name):
                        
                        std = Studnet(name)
                        
                        do_task_1(std)
                        
                        do_task2(std)
                        
                    def do_task_1(std):
                    
                        do_subtask_1(std)
                        
                        do_subtask_2(std)
                        
                    def do_task_2(std):
                    
                        do_subtask_2(std)
                        
                        do_sybtask_2(std)
                        
                   # 1.
                   
                   import threading
                   
                   local_school = threading.local()
                   
                   def process_student():
                   
                        print 'Hello, %s (in %s)' % (local_school.student, threading.current_thread().name)
                        
                   def process_thread(name):
                   
                        local_school.student = name
                        
                        process_student()
                        
                  t1 = threading.Thread(target = process_thread, args = ('Alice',), name = 'Thread-A')
                  
                  t2 = threading.Thread(target = process_thread, args = ('Bob',), name = 'Thread-B')
                  
                  t1.start()
                  
                  t2.start()
                  
                  t1.join()
                  
                  t2.join()
                  
                  # 1.全局变量local_school就是一个ThreadLocal对象，每个Thread对它都是可以读写student属性，但互不影响。
                    2.可以把local_school看成全局变量，但每个属性如local_school.student都是线程的局部变量
                    3.可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理
                    4.可以理解为全局变量local_school是一个dict，不但可以用local_school.student，还可以绑定其他变量
                    5.ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等
                    
                    
                # 进程 VS. 线程
                
                  # 1.通常我们会设计Master-Worker模式，Master负责分配任务，Worker负责折行任务，因此，通常是一个Master，多个Worker
                    2.如果用多进程实现，主进程就是Master，其他进程就是Worker
                    3.如果用多线程实现，主线程就是Master，其实线程就是Worker
                    4.多进程模式最大的优点就是稳定性高，因为一个子进崩溃了，不会影响主进程和其他子进程。
                    
                    
                    
               # 计算密集型 vs. IO密集型
               
                  # 1.是否采用多任务的第二个考虑是任务的类型，我们可以把任务分为计算密集型和IO密集型
                    2.计算密集型任务主要消耗CPU资源，因此，代码运行效率至关重要。
                    3.对于计算密集型任务，最好使C语言来写。
                    4.涉及到网络，磁盘I的O任务都是IO密集型任务，这类任务消耗CPU资源少。
                    
                    
               # 异步IO
               
                  # 1.
                 
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                        
                    
                        
                        
                        
                        
                    
                      
                      
                       
                     
                    
                     
                          
                                
                                
                                
                                
                                
                                
                                
                        
                                
                        
                
                      
                      
                    
                    
                    
        
            
            
            
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
        
        
